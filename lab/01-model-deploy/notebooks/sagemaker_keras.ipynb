{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps SageMaker\n",
    "\n",
    "This notebook contains examples related to manage an end to end ML workflow for packaging ML model for edge environments using SageMaker services:\n",
    "\n",
    "1. SageMaker Training Job\n",
    "2. SageMaker Neo Compile Job\n",
    "3. SageMaker Edge Packaging Job\n",
    "4. SageMaker Model Registry\n",
    "\n",
    "    4.1 Create SageMaker Model Package Group\n",
    "    \n",
    "    4.2 Create SageMaker Model Package\n",
    "    \n",
    "    4.3 Register ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role, image_uris\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import time\n",
    "import traceback\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global configurations\n",
    "\n",
    "Configuration variables used for Training, Compilation and Packaging jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "role_name = \"\"\n",
    "role = \"arn:aws:iam::{}:role/{}\".format(account_id, role_name)\n",
    "kms_alias = \"ml-kms-dev\"\n",
    "kms_key = \"arn:aws:kms:{}:{}:alias/{}\".format(region, account_id, kms_alias)\n",
    "\n",
    "edge_model_name = \"mlops-iot-regressor\"\n",
    "edge_model_version = \"1\"\n",
    "model_package_group = {\n",
    "    \"name\": \"mlops-iot-regressor\",\n",
    "    \"description\": \"model package group used for versioning ml models for edge environments\"\n",
    "}\n",
    "processing_arguments = [\"--input_file\", \"bottle.csv\"]\n",
    "processing_ecr_image_name = \"mlops-iot-processing\"\n",
    "processing_ecr_image_tag = \"latest\"\n",
    "processing_ecr_image = \"{}.dkr.ecr.{}.amazonaws.com/{}:{}\".format(account_id, region, processing_ecr_image_name, processing_ecr_image_tag)\n",
    "sagemaker_framework_version = \"2.4\"\n",
    "sagemaker_python_version = \"py37\"\n",
    "s3_bucket_name = \"isengard-bpistone-mlops-iot-dev\"\n",
    "s3_compiled_files_path = \"output/compiled\"\n",
    "s3_packaged_files_path = \"output/packaged\"\n",
    "s3_processing_artifact_path = \"artifact/processing\"\n",
    "s3_processing_input_files_path = \"input/data\"\n",
    "s3_processing_output_files_path = \"output/data\"\n",
    "s3_training_artifact_path = \"artifact/training\"\n",
    "s3_training_artifact_name = \"sourcedir_dnn.tar.gz\"\n",
    "s3_training_input_files_path = \"output/data\"\n",
    "s3_training_output_files_path = \"output/model\"\n",
    "training_hyperparameters = {\n",
    "    \"epochs\": 10,\n",
    "    \"dataset_percentage\": 100,\n",
    "    \"input_file\": \"bottle.csv\"\n",
    "}\n",
    "\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "instance_count = 1\n",
    "processing_instance_type = \"ml.t3.large\"\n",
    "processing_instance_count = 1\n",
    "platform_arch = \"x86_64\"\n",
    "platform_os: \"LINUX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Processor\n",
    "\n",
    "This method create the processor by using a built-in SageMaker images for SKLearn framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_processor():\n",
    "    try:\n",
    "        processor = Processor(\n",
    "            image_uri=processing_ecr_image,\n",
    "            role=role,\n",
    "            instance_count=processing_instance_count,\n",
    "            instance_type=processing_instance_type,\n",
    "            output_kms_key=kms_key\n",
    "        )\n",
    "\n",
    "        return processor\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing method\n",
    "\n",
    "This method can be used for running a SageMaker Processing Job and train the ML toy model provided by using the artifact stored in the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(processor):\n",
    "    try:\n",
    "        processor.run(\n",
    "            inputs=[\n",
    "                ProcessingInput(input_name=\"input\", source=\"s3://{}/{}\".format(s3_bucket_name, s3_processing_input_files_path), destination=\"/opt/ml/processing/input\")\n",
    "            ],\n",
    "            outputs=[\n",
    "                ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\", destination=\"s3://{}/{}\".format(s3_bucket_name, s3_processing_output_files_path))\n",
    "            ],\n",
    "            arguments=processing_arguments,\n",
    "            wait=True\n",
    "        )\n",
    "        \n",
    "        return processor._current_job_name\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Estimator\n",
    "\n",
    "This method create the estimator by using a built-in SageMaker images for Keras framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_estimator():\n",
    "    try:\n",
    "        estimator = TensorFlow(\n",
    "            entry_point=\"train.py\",\n",
    "            framework_version=sagemaker_framework_version,\n",
    "            py_version=sagemaker_python_version,\n",
    "            source_dir=\"s3://{}/{}/{}\".format(s3_bucket_name,\n",
    "                                              s3_training_artifact_path,\n",
    "                                              s3_training_artifact_name\n",
    "                                              ),\n",
    "            output_path=\"s3://{}/{}\".format(s3_bucket_name,\n",
    "                                            s3_training_output_files_path),\n",
    "            hyperparameters=training_hyperparameters,\n",
    "            enable_sagemaker_metrics=True,\n",
    "            role=role,\n",
    "            instance_count=instance_count,\n",
    "            instance_type=instance_type,\n",
    "            output_kms_key=kms_key\n",
    "        )\n",
    "        \n",
    "        return estimator\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train method\n",
    "\n",
    "This method can be used for running a SageMaker Training Job and train the ML toy model provided by using the artifact stored in the S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(estimator):\n",
    "    try:\n",
    "        estimator.fit(\n",
    "            inputs={\n",
    "                \"train\": \"s3://{}/{}\".format(\n",
    "                    s3_bucket_name,\n",
    "                    s3_training_input_files_path\n",
    "                )\n",
    "            },\n",
    "            logs=\"Rules\"\n",
    "        )\n",
    "        \n",
    "        return estimator._current_job_name\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile method\n",
    "\n",
    "This method can be used for running a SageMaker Compilation Job with Neo for compiling the model for the target instance defined in the configuration parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_neo(training_job_name):\n",
    "    \n",
    "    try:\n",
    "        neo_job_name = \"sagemaker-neo-job-keras-{}\".format(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "        LOGGER.info(\"{}\".format('s3://{}/{}/{}/output/model.tar.gz'.format(\n",
    "                    s3_bucket_name,\n",
    "                    s3_training_input_files_path,\n",
    "                    training_job_name\n",
    "                )))\n",
    "\n",
    "        sagemaker_client.create_compilation_job(\n",
    "            CompilationJobName=neo_job_name,\n",
    "            RoleArn=role,\n",
    "            InputConfig={\n",
    "                'S3Uri': 's3://{}/{}/{}/output/model.tar.gz'.format(\n",
    "                    s3_bucket_name,\n",
    "                    s3_training_input_files_path,\n",
    "                    training_job_name\n",
    "                ),\n",
    "                'DataInputConfig': '{\"input_token\": [1, 1, 1, 1]}',\n",
    "                'Framework': 'KERAS'\n",
    "            },\n",
    "            OutputConfig={\n",
    "                'S3OutputLocation': \"s3://{}/{}/{}\".format(\n",
    "                    s3_bucket_name,\n",
    "                    s3_compiled_files_path,\n",
    "                    neo_job_name\n",
    "                ),\n",
    "                'TargetPlatform': { \n",
    "                    'Os': platform_os, \n",
    "                    'Arch': platform_arch,\n",
    "                },\n",
    "                'KmsKeyId': kms_key\n",
    "            },\n",
    "            StoppingCondition={'MaxRuntimeInSeconds': 900}\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            resp = sagemaker_client.describe_compilation_job(CompilationJobName=neo_job_name)\n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            if resp['CompilationJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "                LOGGER.info(\"{}: Running...\".format(current_time))\n",
    "            else:\n",
    "                LOGGER.info(\"{} - {}\".format(neo_job_name, resp['CompilationJobStatus']))\n",
    "\n",
    "                if resp['CompilationJobStatus'] == \"FAILED\":\n",
    "                    if \"FailureReason\" in resp:\n",
    "                        LOGGER.info(\"{}\".format(resp[\"FailureReason\"]))\n",
    "                break\n",
    "            time.sleep(60)\n",
    "\n",
    "        return neo_job_name\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "\n",
    "        LOGGER.error(\"[ERROR]: {}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package method\n",
    "\n",
    "This method can be used for running a SageMaker Edge Packaging Job for creating the artifact ready to be deployed on the target edge device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_edge_manager(neo_job_name):\n",
    "    try:\n",
    "        edge_manager_job_name = \"edge-manager-job-keras-{}\".format(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "        resp = sagemaker_client.create_edge_packaging_job(\n",
    "            EdgePackagingJobName=edge_manager_job_name,\n",
    "            CompilationJobName=neo_job_name,\n",
    "            ModelName=edge_model_name,\n",
    "            ModelVersion=edge_model_version,\n",
    "            RoleArn=role,\n",
    "            OutputConfig={\n",
    "                'S3OutputLocation': \"s3://{}/{}/{}\".format(\n",
    "                    s3_bucket_name,\n",
    "                    s3_packaged_files_path,\n",
    "                    edge_manager_job_name\n",
    "                ),\n",
    "                'KmsKeyId': kms_key\n",
    "            }\n",
    "        )\n",
    "        while True:\n",
    "            resp = sagemaker_client.describe_edge_packaging_job(EdgePackagingJobName=edge_manager_job_name)\n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            if resp['EdgePackagingJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "                LOGGER.info(\"{}: Running...\".format(current_time))\n",
    "            else:\n",
    "                LOGGER.info(\"{}\".format(resp))\n",
    "                LOGGER.info(\"{} - {}\".format(edge_manager_job_name, resp['EdgePackagingJobStatus']))\n",
    "                \n",
    "                break\n",
    "            time.sleep(60)\n",
    "            \n",
    "        return edge_manager_job_name\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "\n",
    "        LOGGER.error(\"[ERROR]: {}\".format(stacktrace))\n",
    "        print(\"[ERROR]: {}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registry Section\n",
    "\n",
    "This section contains the methods for managing SageMaker Model Registry\n",
    "\n",
    "1. Describe Model Package Group\n",
    "2. Create Model Package Group\n",
    "3. Create Model Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Model Package Group\n",
    "\n",
    "This method can be used for checking if a Model Package Group exists in the SageMaker Model Registry environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model_package_group():\n",
    "    try:\n",
    "        LOGGER.info(\"Describing {}\".format(model_package_group[\"name\"]))\n",
    "\n",
    "        response = sagemaker_client.describe_model_package_group(\n",
    "            ModelPackageGroupName=model_package_group[\"name\"]\n",
    "        )\n",
    "\n",
    "        LOGGER.info(\"{}\".format(response))\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Package Group\n",
    "\n",
    "This method can be used for creating a Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_package_group(tags=[]):\n",
    "    try:\n",
    "        LOGGER.info(\"Creating {}\".format(model_package_group[\"name\"]))\n",
    "\n",
    "        response = sagemaker_client.create_model_package_group(\n",
    "            ModelPackageGroupName=model_package_group[\"name\"],\n",
    "            ModelPackageGroupDescription=model_package_group[\"description\"],\n",
    "            Tags=tags\n",
    "        )\n",
    "\n",
    "        LOGGER.info(\"{}\".format(response))\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Package\n",
    "\n",
    "This method can be used for registering a new model version, as Model Package, in the previously created Model Package Group\n",
    "\n",
    "For registering a Model Package, required informations are:\n",
    "\n",
    "1. ECR image uri: the image uri that eventually can be used for performing inference on SageMaker. In our case, we are taking the XGBoost image that will not be used on the Edge device\n",
    "2. Model Url: S3 path to the model. In our case this is the path to the packaged model\n",
    "3. Job Name: SageMaker Job name used for tracking the model lineage, the sequence of the operations that led to the trained model\n",
    "4. Approval Status: Status to assign to the registered model. Three possible status: PendingManualApproval, Rejected, Approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_model_package(image_uri, model_url, training_job_name, approval_status=\"PendingManualApproval\", tags=[]):\n",
    "    try:\n",
    "        modelpackage_inference_specification = {\n",
    "            \"InferenceSpecification\": {\n",
    "                \"Containers\": [\n",
    "                    {\n",
    "                        \"Image\": image_uri,\n",
    "                        \"ModelDataUrl\": model_url\n",
    "                    }\n",
    "                ],\n",
    "                \"SupportedContentTypes\": [\"text/csv\"],\n",
    "                \"SupportedResponseMIMETypes\": [\"text/csv\"],\n",
    "            }\n",
    "        }\n",
    "\n",
    "        create_model_package_input_dict = {\n",
    "            \"ModelPackageGroupName\": model_package_group[\"name\"],\n",
    "            \"ModelPackageDescription\": \"Model for {}\".format(model_package_group[\"description\"]),\n",
    "            \"ModelApprovalStatus\": approval_status,\n",
    "            \"Tags\": tags\n",
    "        }\n",
    "        create_model_package_input_dict.update(modelpackage_inference_specification)\n",
    "        create_mode_package_response = sagemaker_client.create_model_package(**create_model_package_input_dict)\n",
    "        model_package_arn = create_mode_package_response[\"ModelPackageArn\"]\n",
    "\n",
    "        LOGGER.info('ModelPackage Version ARN : {}'.format(model_package_arn))\n",
    "\n",
    "        return model_package_arn\n",
    "\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update model package status\n",
    "\n",
    "This method can be used for updating the approval status of a registered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_package_status(model_package_arn, status, description=\"\"):\n",
    "    try:\n",
    "        LOGGER.info(\"Updating {}\".format(model_package_arn))\n",
    "        LOGGER.info(\"To status {}\".format(status))\n",
    "        \n",
    "        response = sagemaker_client.update_model_package(\n",
    "            ModelPackageArn=model_package_arn,\n",
    "            ModelApprovalStatus=status,\n",
    "            ApprovalDescription=description\n",
    "        )\n",
    "        \n",
    "        LOGGER.info(\"{}\".format(response))\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Model Packages\n",
    "\n",
    "This method can be used for listing all the registered models in a Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_model_packages(next_token=None):\n",
    "    try:\n",
    "        if next_token is None:\n",
    "            results = sagemaker_client.list_model_packages(\n",
    "                ModelPackageGroupName=model_package_group[\"name\"],\n",
    "                SortBy='CreationTime',\n",
    "                SortOrder='Descending',\n",
    "                MaxResults=100\n",
    "            )\n",
    "        else:\n",
    "            results = sagemaker_client.list_model_packages(\n",
    "                ModelPackageGroupName=model_package_group[\"name\"],\n",
    "                SortBy='CreationTime',\n",
    "                SortOrder='Descending',\n",
    "                MaxResults=100,\n",
    "                NextToken=next_token\n",
    "            )\n",
    "\n",
    "        model_package_groups = []\n",
    "        model_package_arns = []\n",
    "        model_package_descriptions = []\n",
    "        model_package_creation_time = []\n",
    "        model_package_approval_status = []\n",
    "\n",
    "        if \"ModelPackageSummaryList\" in results:\n",
    "            for el in results[\"ModelPackageSummaryList\"]:  \n",
    "                model_package_groups.append(model_package_group[\"name\"])\n",
    "                model_package_arns.append(el[\"ModelPackageArn\"])\n",
    "                model_package_descriptions.append(el[\"ModelPackageDescription\"])\n",
    "                model_package_creation_time.append(el[\"CreationTime\"])\n",
    "                model_package_approval_status.append(el[\"ModelApprovalStatus\"])\n",
    "                \n",
    "        data = {\n",
    "            'Model Package Group': model_package_groups, \n",
    "            'Package ARN': model_package_arns,\n",
    "            'Package Description': model_package_descriptions,\n",
    "            'Package Cration Time': model_package_creation_time,\n",
    "            'Package Approval Status': model_package_approval_status\n",
    "        }\n",
    "                \n",
    "        if \"NextToken\" in results and results[\"NextToken\"] != \"\":\n",
    "            tmp_data = list_model_packages(results[\"NextToken\"])\n",
    "            \n",
    "            data[\"Model Package Group\"] += tmp_data[\"Model Package Group\"]\n",
    "            data[\"Package ARN\"] += tmp_data[\"Package ARN\"]\n",
    "            data[\"Package Description\"] += tmp_data[\"Package Description\"]\n",
    "            data[\"Package Cration Time\"] += tmp_data[\"Package Cration Time\"]\n",
    "            data[\"Package Approval Status\"] += tmp_data[\"Package Approval Status\"]\n",
    "        \n",
    "        else:\n",
    "            return data\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = create_preprocessing_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_name = process(processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = create_training_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = train(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_job_name = compile_neo(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_manager_job_name = package_edge_manager(neo_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model package group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_package_group = describe_model_package_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_model_package_group == \"\":\n",
    "    create_model_package_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(framework='tensorflow', image_scope=\"inference\", region='eu-west-1', version='2.2')\n",
    "model_url = \"s3://{}/{}/{}/model-{}_{}.tar.gz\".format(\n",
    "    S3_BUCKET_NAME,\n",
    "    S3_COMPILED_FILES_PATH,\n",
    "    neo_job_name,\n",
    "    \"LINUX\",\n",
    "    \"X86_64\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model_package(image_uri, model_url, neo_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â List registered models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list_model_packages()\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update package status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_model_package_status(df[\"Package ARN\"][0], \"Approved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "377749bc69013d59c4cecceb2067ba27f3d348746836b844696e5065ebbdc432"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('mlops-iot': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
