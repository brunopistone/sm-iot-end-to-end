{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you will do:\n",
    " - Create/Run an Amazon SageMaker Pipeline [SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines.html)\n",
    " - Compute the thresholds, used by the applicatio to classify the predictions as anomalies or normal behavior\n",
    "\n",
    "\n",
    "The following diagram shows all the steps we're going to execute:  \n",
    "![Pipeline](./../imgs/ggv2_lab2_train_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1/3 - Setup\n",
    "Here we'll import some libraries and define some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('./../mlpipelines'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.pipeline import get_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2/3 - Create Amazon SageMaker Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "model_package_group_name = \"mlops-iot-package-group\"\n",
    "\n",
    "preprocessing_framework_version = \"0.23-1\"\n",
    "preprocessing_instance_type = \"ml.m5.xlarge\"\n",
    "preprocessing_instance_count = 1\n",
    "preprocessing_input_files_path = \"data/input\"\n",
    "preprocessing_entrypoint = \"./../algorithms/preprocessing/preprocessing.py\"\n",
    "\n",
    "postprocessing_output_files_path = \"data/output\"\n",
    "\n",
    "training_framework_version = \"1.6.0\"\n",
    "training_python_version = \"py3\"\n",
    "training_instance_type = \"ml.c5.4xlarge\"\n",
    "training_instance_count = 1\n",
    "training_hyperparameters = {\n",
    "    'k_fold_splits': 6,\n",
    "    'k_index_only': 3, # after running some experiments with this dataset, it makes sense to fix it\n",
    "    'num_epochs': 20,\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 0.0001,\n",
    "    'dropout_rate': 0.001\n",
    "}\n",
    "training_metrics = [\n",
    "    {'Name': 'train_loss:mse', 'Regex': ' train_loss=(\\S+);'},\n",
    "    {'Name': 'test_loss:mse', 'Regex': ' test_loss=(\\S+);'}\n",
    "]\n",
    "training_entrypoint = \"./../algorithms/training/wind_turbine.py\"\n",
    "\n",
    "transform_instance_type = \"ml.c5.xlarge\"\n",
    "transform_instance_count = 2\n",
    "\n",
    "s3_bucket_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(\n",
    "    region,\n",
    "    model_package_group_name,\n",
    "    preprocessing_framework_version,\n",
    "    preprocessing_instance_count,\n",
    "    preprocessing_instance_type,\n",
    "    preprocessing_input_files_path,\n",
    "    preprocessing_entrypoint,\n",
    "    postprocessing_output_files_path,\n",
    "    training_framework_version,\n",
    "    training_python_version,\n",
    "    training_instance_count,\n",
    "    training_instance_type,\n",
    "    training_entrypoint,\n",
    "    transform_instance_count,\n",
    "    transform_instance_type,\n",
    "    s3_bucket_name,\n",
    "    training_hyperparameters,\n",
    "    training_metrics,\n",
    "    role,\n",
    "    pipeline_name=\"MLOpsIotBuildTrain\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or update SageMaker pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training pipeline and overriding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3/3 - Compute the threshold based on MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the predictions & Compute MAE/thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_execution_arn = execution.arn\n",
    "print(pipeline_execution_arn)\n",
    "\n",
    "execution_id = pipeline_execution_arn.split('/')[-1]\n",
    "training_jobs = sm_client.list_training_jobs(NameContains=execution_id, StatusEquals='Completed')['TrainingJobSummaries']\n",
    "\n",
    "assert(len(training_jobs) == 1) # it must have exactly one training job\n",
    "training_job_name=training_jobs[0]['TrainingJobName']\n",
    "\n",
    "# We will recreate the estimator, based on the training job\n",
    "estimator = sagemaker.estimator.Estimator.attach(\n",
    "    training_job_name=training_job_name, \n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "tokens = input_data.split('/', 3)\n",
    "sagemaker_session.download_data(bucket=bucket_name, key_prefix='data/output/eval/', path='./../data/preds/')\n",
    "sagemaker_session.download_data(bucket=bucket_name, key_prefix=tokens[3], path='./../data/input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "x_inputs = np.vstack([np.load(i) for i in glob.glob('./../data/input/*.npy')])\n",
    "y_preds = np.vstack([np.load(i) for i in glob.glob('./../data/preds/*.out')])\n",
    "\n",
    "n_samples,n_features,n_rows,n_cols = x_inputs.shape\n",
    "\n",
    "x_inputs = x_inputs.reshape(n_samples, n_features, n_rows*n_cols).transpose((0,2,1))\n",
    "y_preds = y_preds.reshape(n_samples, n_features, n_rows*n_cols).transpose((0,2,1))\n",
    "\n",
    "mae_loss = np.mean(np.abs(y_preds - x_inputs), axis=1).transpose((1,0))\n",
    "mae_loss[np.isnan(mae_loss)] = 0\n",
    "\n",
    "thresholds = np.mean(mae_loss, axis=1)\n",
    "\n",
    "if not(os.path.exists(\"./../data/statistics\")):\n",
    "    os.mkdir(\"./../data/statistics\")\n",
    "\n",
    "np.save('./../data/statistics/thresholds.npy', thresholds)\n",
    "print(\",\".join(thresholds.astype(str)))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
